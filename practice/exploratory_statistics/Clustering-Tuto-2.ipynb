{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Tuto 2\n",
    "\n",
    "Here we play with a 2D dataset and several clustering methods\n",
    "\n",
    "The 2D dataset is created from a collection of Argo temperature and salinity profiles interpolated on Standard Depth Levels\n",
    "\n",
    "Clustering methods are: DBSCAN and KMEANS from scikit-learn\n",
    "\n",
    "(c) G. Maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "*First, let's make sure the Python env is correct to run this notebook*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/psmkfjds7xsc4kjsz66ghldr000nsn/T/tmpphhnez2i/utils.py:44: UserWarning: \n",
      "Running on your own environment\n",
      "  warnings.warn(\"\\nRunning on your own environment\")\n"
     ]
    }
   ],
   "source": [
    "import os, sys, urllib, tempfile\n",
    "with tempfile.TemporaryDirectory() as local:\n",
    "    sys.path.append(local)\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/obidam/ds2-2024/main/utils.py\", os.path.join(local, \"utils.py\"))\n",
    "    from utils import check_up_env\n",
    "    check_up_env(with_tuto=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import section\n",
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\", palette=\"deep\", color_codes=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "from tuto_tools import create_map\n",
    "from intake import open_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "From Google cloud storage [see specific tuto here](https://github.com/obidam/ds2-2022/blob/main/practice/environment/02-Access_to_data_in_the_cloud.ipynb).\n",
    "\n",
    "Use in-situ measurements from Argo floats, interpolated on standard depth levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_url = 'https://raw.githubusercontent.com/obidam/ds2-2024/main/ds2_data_catalog.yml'\n",
    "cat = open_catalog(catalog_url)\n",
    "ds = cat['argo_global_sdl_homogeneous'].read_chunked()\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This dataset holds: %.3f GB' % (ds.nbytes / 1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a 2D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eg 1: Select temperature and salinity from a single depth level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = -250 # Depth level to select\n",
    "feat_0 = ds['TEMP'].sel(DEPTH=z, method='nearest')\n",
    "feat_1 = ds['PSAL'].sel(DEPTH=z, method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eg 2: Select temperature from two distinct depth levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_0 = ds['TEMP'].sel(DEPTH=0, method='nearest')\n",
    "feat_1 = ds['TEMP'].sel(DEPTH=-1000, method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new xarray DataSet to hold analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = xr.concat([feat_0, feat_1], dim='N_FEATURES').chunk(chunks={'N_PROF':1000})\n",
    "RES = RES.rename('ARGO')\n",
    "# Remove obsolete attributes:\n",
    "for a in RES.attrs.copy(): \n",
    "    del RES.attrs[a]\n",
    "# Add feature names:\n",
    "RES.attrs['feature_0'] = \"%s at %0.2fm depth\"%(feat_0.name,feat_0['DEPTH'])\n",
    "RES.attrs['feature_1'] = \"%s at %0.2fm depth\"%(feat_1.name,feat_1['DEPTH'])\n",
    "# We're good:\n",
    "print(RES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possibly sub-sample the array for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 # Nb of sample to keep\n",
    "# print(len(RES.N_PROF))\n",
    "ii = np.random.choice(range(len(RES.N_PROF)), n, replace=False)\n",
    "RES = RES.isel(N_PROF=ii).chunk({'N_PROF':n/10})\n",
    "print(RES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(0.25), dpi=120, facecolor='w', edgecolor='k')\n",
    "sns.histplot(RES.isel(N_FEATURES=0), stat='density', kde=True, ax=ax[0])\n",
    "sns.histplot(RES.isel(N_FEATURES=1), stat='density', kde=True, ax=ax[1])\n",
    "ax[0].set_xlabel(RES.attrs['feature_0']);\n",
    "ax[1].set_xlabel(RES.attrs['feature_1']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal and 2D PDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (sns.jointplot(x=RES.isel(N_FEATURES=0), y=RES.isel(N_FEATURES=1), kind=\"kde\", color=\"k\")\n",
    "     .set_axis_labels(RES.attrs['feature_0'], RES.attrs['feature_1'])\n",
    "     .plot_joint(sns.kdeplot, zorder=0, n_levels=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Plot conditional PDFs: p(x1|x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering in 2D\n",
    "\n",
    "Clearly from the figure above, one can see that the dataset exhibits several modes. \n",
    "In other words, data samples agregated into several clusters.\n",
    "\n",
    "Let's identify them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data (normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "X = RES.values.T \n",
    "print(X.shape) # Ensure we have sampling x features\n",
    "\n",
    "# Fit the scaler object:\n",
    "scaler = preprocessing.StandardScaler()\n",
    "%time scaler = scaler.fit(X)\n",
    "\n",
    "# The mean and std profiles are in the scaler object properties:\n",
    "X_ave = scaler.mean_\n",
    "X_std = scaler.scale_\n",
    "print(\"Data mean and std:\", X_ave, X_std)\n",
    "\n",
    "# Normalize data:\n",
    "Xn = scaler.transform(X) \n",
    "# print(Xn.shape)\n",
    "\n",
    "# Add results to the dataset:\n",
    "RES['TEMPnorm'] = xr.DataArray(Xn[:,0], dims='N_PROF')\n",
    "RES['PSALnorm'] = xr.DataArray(Xn[:,1], dims='N_PROF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.1, min_samples=50).fit(Xn)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "\n",
    "# Add results to the dataset:\n",
    "RES['DBSCAN'] = xr.DataArray(labels, dims='N_PROF')\n",
    "\n",
    "print(RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=plt.figaspect(0.6), dpi=90, facecolor='w', edgecolor='k')\n",
    "\n",
    "# \n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "plt.plot(Xn[:,1],Xn[:,0],'.',markersize=1,color=[0.3]*3)\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 0.2]\n",
    "#     print \"Cluster: \", k, col\n",
    "    \n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = Xn[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 1], xy[:, 0], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor=[0.5]*3, markersize=3, markeredgewidth=0.5, label=\"Class %i\"%(k))\n",
    "\n",
    "#     xy = Xn[class_member_mask & ~core_samples_mask]\n",
    "#     plt.plot(xy[:, 1], xy[:, 0], 'o', markerfacecolor=tuple(col),\n",
    "#              markeredgecolor='none', markersize=3, label=\"Noise class %i\"%(k))\n",
    "\n",
    "plt.xlim(-3,9)\n",
    "plt.ylim(-3,3)\n",
    "plt.xlabel(RES.attrs['feature_0'])\n",
    "plt.ylabel(RES.attrs['feature_1'])\n",
    "plt.title('Estimated number of clusters: %d (DBSCAN)' % n_clusters_)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, proj, ax = create_map(extent=[-180, 180, -90, 90])\n",
    "\n",
    "# plt.scatter(RES.LONGITUDE,RES.LATITUDE,5,RES.DBSCAN,transform=proj)\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 0.2]\n",
    "#     print \"Cluster: \", k, col\n",
    "    \n",
    "    class_member_mask = (RES.DBSCAN == k)\n",
    "\n",
    "    plt.plot(RES.LONGITUDE[class_member_mask],\n",
    "                RES.LATITUDE[class_member_mask],\n",
    "                 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='none', markersize=2,  \n",
    "             label=\"Class %i\"%(k), transform=proj)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d (DBSCAN)' % n_clusters_)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%time kmeans = KMeans(n_clusters=6, random_state=0, n_init=10).fit(Xn)\n",
    "labels = kmeans.predict(Xn)\n",
    "n_clusters_ = kmeans.n_clusters\n",
    "kmeans.cluster_centers_.shape\n",
    "\n",
    "# Add results to the dataset:\n",
    "RES['KMEANS'] = xr.DataArray(labels, dims='N_PROF')\n",
    "\n",
    "print(RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=plt.figaspect(0.6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "unique_labels = np.unique(RES['KMEANS'])\n",
    "n_clusters_ = unique_labels.shape[0]\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "#     print \"Cluster: \", k, col\n",
    "    class_members = RES['KMEANS'] == k\n",
    "#     plt.plot(RES['PSALnorm'][class_members], RES['TEMPnorm'][class_members], '.', \n",
    "#              markerfacecolor=tuple(col), markeredgecolor='none')\n",
    "\n",
    "#     cluster_center = kmeans.cluster_centers_[k,:]\n",
    "#     plt.plot(cluster_center[1], cluster_center[0], 'o', markerfacecolor=tuple(col),\n",
    "#              markeredgecolor='k', markersize=14, label='Class %i'%(k))\n",
    "    \n",
    "    plt.plot(RES.sel(N_FEATURES=1)[class_members], RES.sel(N_FEATURES=0)[class_members], '.', \n",
    "             markerfacecolor=tuple(col), markeredgecolor='none', label='Class %i'%(k))\n",
    "\n",
    "    cluster_center = scaler.inverse_transform(kmeans.cluster_centers_[k,:][np.newaxis,:])[0]\n",
    "    plt.plot(cluster_center[1], cluster_center[0], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=10, label='Class center #%i'%(k))\n",
    "\n",
    "# plt.xlim(-3,9)\n",
    "# plt.ylim(-3,3)\n",
    "plt.xlabel(RES.attrs['feature_0'])\n",
    "plt.ylabel(RES.attrs['feature_1'])\n",
    "plt.title('Number of clusters: %i (KMEANS)' % n_clusters_)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, proj, ax = create_map(extent=[-180, 180, -90, 90])\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 0.2]\n",
    "    print(\"Cluster: \", k, col)\n",
    "    \n",
    "    class_member_mask = (RES.KMEANS == k)\n",
    "\n",
    "    plt.plot(RES.LONGITUDE[class_member_mask],\n",
    "                RES.LATITUDE[class_member_mask],\n",
    "                 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='none', markersize=2,  \n",
    "             label=\"Class %i\"%(k), transform=proj)\n",
    "\n",
    "plt.title('Number of clusters: %d (KMEANS)' % n_clusters_)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Implement and visualize results from another clusterring method available in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (py38)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
